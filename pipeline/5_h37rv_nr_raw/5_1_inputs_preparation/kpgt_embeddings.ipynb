{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a7cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d94581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def unique_dir_name():\n",
    "    return datetime.datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def smiles_to_embeddings(smiles, gpu, kpgt_root, env_python, model_path, config_name=\"base\"):\n",
    "    folder = unique_dir_name()\n",
    "    datasets_dir = Path(kpgt_root) / \"datasets\" / folder\n",
    "    datasets_dir.mkdir(parents=True)\n",
    "\n",
    "    csv_path = datasets_dir / f\"{folder}.csv\"\n",
    "    pd.DataFrame({\"Class\": [0]*len(smiles), \"smiles\": smiles}).to_csv(csv_path, index=False)\n",
    "\n",
    "    original_path = Path.cwd()\n",
    "    script_dir = Path(kpgt_root) / \"scripts\"\n",
    "    os.chdir(script_dir)\n",
    "\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            env_python,\n",
    "            str(script_dir / \"preprocess_downstream_dataset.py\"),\n",
    "            \"--data_path\", str(Path(kpgt_root) / \"datasets\"),\n",
    "            \"--dataset\", folder\n",
    "        ], check=True)\n",
    "\n",
    "        print(\"ðŸ§  Extracting features...\")\n",
    "\n",
    "        subprocess.run([\n",
    "            env_python,\n",
    "            str(script_dir / \"extract_features.py\"),\n",
    "            \"--config\", config_name,\n",
    "            \"--model_path\", str(model_path),\n",
    "            \"--data_path\", str(Path(kpgt_root) / \"datasets\"),\n",
    "            \"--gpu\", str(gpu),\n",
    "            \"--dataset\", folder\n",
    "        ], check=True)\n",
    "\n",
    "    finally:\n",
    "        os.chdir(original_path)\n",
    "\n",
    "    # Load embeddings\n",
    "    embeddings_npz = datasets_dir / \"kpgt_base.npz\"\n",
    "    data = np.load(embeddings_npz)\n",
    "    fps_array = data[\"fps\"]\n",
    "\n",
    "    # Clean up\n",
    "    import shutil\n",
    "    shutil.rmtree(datasets_dir)\n",
    "\n",
    "    return fps_array\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def compute_kpgt_embeddings_for_dataset(csv_paths, output_fp_cache_path, gpu, kpgt_root, env_python, model_path):\n",
    "    all_smiles = set()\n",
    "    for path in csv_paths:\n",
    "        df = pd.read_csv(path)\n",
    "        all_smiles.update(df[\"smiles\"])\n",
    "\n",
    "    all_smiles = sorted(list(all_smiles))\n",
    "    print(f\"ðŸ§¬ Total unique SMILES: {len(all_smiles)}\")\n",
    "\n",
    "    fps_array = smiles_to_embeddings(all_smiles, gpu=gpu, kpgt_root=kpgt_root,\n",
    "                                     env_python=env_python, model_path=model_path)\n",
    "\n",
    "    smiles_to_fp = {smi: fps_array[i] for i, smi in enumerate(all_smiles)}\n",
    "\n",
    "    with open(output_fp_cache_path, \"wb\") as f:\n",
    "        pickle.dump(smiles_to_fp, f)\n",
    "\n",
    "    print(f\"âœ… Embeddings saved to: {output_fp_cache_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a945b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 25 CSV files for H37Rv\n",
      "ðŸ§¬ Total unique SMILES: 14187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorchUsing backend: pytorch\n",
      "\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorchUsing backend: pytorch\n",
      "\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=32)]: Done 744 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=32)]: Done 2144 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=32)]: Done 3944 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=32)]: Done 6144 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=32)]: Done 8744 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=32)]: Done 11744 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=32)]: Done 14124 out of 14187 | elapsed:   24.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 14187 out of 14187 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graphs\n",
      "extracting fingerprints\n",
      "saving fingerprints\n",
      "extracting molecular descriptors\n",
      "ðŸ§  Extracting features.../14187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted features were saved at /home/malves/predator/KPGT/datasets//16-04-2025_01-21-09/kpgt_base.npz\n",
      "âœ… Embeddings saved to: /home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/h37rv/kpgt_embeddings_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# --- Set up root paths ---\n",
    "SCRIPT_DIR = os.getcwd()\n",
    "REPO_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, \"..\", \"..\", \"..\"))\n",
    "cv_root = os.path.join(REPO_ROOT, \"data\", \"cv\", \"raw_h37rv_nr\", \"folds\")\n",
    "h37rv_root = os.path.join(cv_root, \"h37rv\")\n",
    "\n",
    "# --- KPGT setup (based on your original structure) ---\n",
    "KPGT_ROOT = os.path.expanduser(\"~/predator/KPGT\")  # /home/malves/predator/KPGT\n",
    "ENV_PYTHON = os.path.expanduser(\"~/miniconda3/envs/KPGT/bin/python\")  # /home/malves/miniconda3/envs/KPGT/bin/python\n",
    "MODEL_PATH = os.path.join(KPGT_ROOT, \"models\", \"pretrained\", \"base\", \"base.pth\")\n",
    "\n",
    "# --- Find CSVs ---\n",
    "csv_paths = glob(os.path.join(h37rv_root, \"h37rv_*.csv\"))\n",
    "print(\"ðŸ“„ Found\", len(csv_paths), \"CSV files for H37Rv\")\n",
    "\n",
    "# --- Compute embeddings ---\n",
    "compute_kpgt_embeddings_for_dataset(\n",
    "    csv_paths=csv_paths,\n",
    "    output_fp_cache_path=os.path.join(h37rv_root, \"kpgt_embeddings_cache.pkl\"),\n",
    "    gpu=0\n",
    "    kpgt_root=KPGT_ROOT,\n",
    "    env_python=ENV_PYTHON,\n",
    "    model_path=MODEL_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61ab24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 25 CSV files for RAW\n",
      "ðŸ§¬ Total unique SMILES: 18780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=32)]: Done 936 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=32)]: Done 2336 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=32)]: Done 4136 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=32)]: Done 6336 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=32)]: Done 8936 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=32)]: Done 11936 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=32)]: Done 15336 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=32)]: Done 18780 out of 18780 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graphs\n",
      "extracting fingerprints\n",
      "saving fingerprints\n",
      "extracting molecular descriptors\n",
      "ðŸ§  Extracting features.../18780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted features were saved at /home/malves/predator/KPGT/datasets//16-04-2025_00-47-00/kpgt_base.npz\n",
      "âœ… Embeddings saved to: /home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/raw/kpgt_embeddings_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# --- Assuming SCRIPT_DIR, REPO_ROOT already defined ---\n",
    "SCRIPT_DIR = os.getcwd()\n",
    "REPO_ROOT = os.path.abspath(os.path.join(SCRIPT_DIR, \"..\", \"..\", \"..\"))\n",
    "\n",
    "cv_root = os.path.join(REPO_ROOT, \"data\", \"cv\", \"raw_h37rv_nr\", \"folds\")\n",
    "raw_root = os.path.join(cv_root, \"raw\")\n",
    "\n",
    "# --- KPGT setup ---\n",
    "KPGT_ROOT = os.path.expanduser(\"~/predator/KPGT\")\n",
    "ENV_PYTHON = os.path.expanduser(\"~/miniconda3/envs/KPGT/bin/python\")\n",
    "MODEL_PATH = os.path.join(KPGT_ROOT, \"models\", \"pretrained\", \"base\", \"base.pth\")\n",
    "\n",
    "# --- Find CSVs ---\n",
    "csv_paths = glob(os.path.join(raw_root, \"raw_*.csv\"))\n",
    "print(\"ðŸ“„ Found\", len(csv_paths), \"CSV files for RAW\")\n",
    "\n",
    "# --- Compute embeddings ---\n",
    "compute_kpgt_embeddings_for_dataset(\n",
    "    csv_paths=csv_paths,\n",
    "    output_fp_cache_path=os.path.join(raw_root, \"kpgt_embeddings_cache.pkl\"),\n",
    "    gpu=0,\n",
    "    kpgt_root=KPGT_ROOT,\n",
    "    env_python=ENV_PYTHON,\n",
    "    model_path=MODEL_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e31c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 25 CSV files for NR\n",
      "ðŸ§¬ Total unique SMILES: 18402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "[Parallel(n_jobs=32)]: Done 162 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=32)]: Done 1032 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=32)]: Done 2432 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=32)]: Done 4232 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=32)]: Done 6432 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=32)]: Done 9032 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=32)]: Done 12032 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=32)]: Done 15432 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=32)]: Done 18402 out of 18402 | elapsed:   29.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graphs\n",
      "extracting fingerprints\n",
      "saving fingerprints\n",
      "extracting molecular descriptors\n",
      "ðŸ§  Extracting features.../18402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted features were saved at /home/malves/predator/KPGT/datasets//16-04-2025_01-36-42/kpgt_base.npz\n",
      "âœ… Embeddings saved to: /home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/nr/kpgt_embeddings_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "cv_root = os.path.join(REPO_ROOT, \"data\", \"cv\", \"raw_h37rv_nr\", \"folds\")\n",
    "nr_root = os.path.join(cv_root, \"nr\")\n",
    "\n",
    "# --- KPGT setup ---\n",
    "KPGT_ROOT = os.path.expanduser(\"~/predator/KPGT\")\n",
    "ENV_PYTHON = os.path.expanduser(\"~/miniconda3/envs/KPGT/bin/python\")\n",
    "MODEL_PATH = os.path.join(KPGT_ROOT, \"models\", \"pretrained\", \"base\", \"base.pth\")\n",
    "\n",
    "# --- Find CSVs ---\n",
    "csv_paths = glob(os.path.join(nr_root, \"nr_*.csv\"))\n",
    "print(\"ðŸ“„ Found\", len(csv_paths), \"CSV files for NR\")\n",
    "\n",
    "# --- Compute embeddings ---\n",
    "compute_kpgt_embeddings_for_dataset(\n",
    "    csv_paths=csv_paths,\n",
    "    output_fp_cache_path=os.path.join(nr_root, \"kpgt_embeddings_cache.pkl\"),\n",
    "    gpu=0,\n",
    "    kpgt_root=KPGT_ROOT,\n",
    "    env_python=ENV_PYTHON,\n",
    "    model_path=MODEL_PATH\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf24beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predinhib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
