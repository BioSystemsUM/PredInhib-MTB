{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47a7cac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import subprocess\n",
    "import datetime\n",
    "import os\n",
    "from glob import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8d94581",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Unique folder generator for temporary dataset directories\n",
    "def unique_dir_name():\n",
    "    now = datetime.datetime.now()\n",
    "    return str(now.strftime(\"%d-%m-%Y_%H-%M-%S\"))\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# KPGT embedding function (replaces RDKit fingerprinting)\n",
    "def smiles_to_embeddings(smiles, gpu):\n",
    "    folder = unique_dir_name()\n",
    "    dataset_path = f'/home/malves/predator/KPGT/datasets/{folder}/'\n",
    "    os.makedirs(dataset_path)\n",
    "\n",
    "    df = pd.DataFrame({'Class': [0]*len(smiles), 'smiles': smiles})\n",
    "    df.to_csv(f'{dataset_path}{folder}.csv', index=False)\n",
    "\n",
    "    original_path = os.getcwd()\n",
    "    script_path = '/home/malves/predator/KPGT/scripts/preprocess_downstream_dataset.py'\n",
    "    os.chdir(os.path.dirname(script_path))\n",
    "\n",
    "    try:\n",
    "        subprocess.run([\n",
    "            '/home/malves/miniconda3/envs/KPGT/bin/python', script_path,\n",
    "            '--data_path', '/home/malves/predator/KPGT/datasets',\n",
    "            '--dataset', folder\n",
    "        ])\n",
    "        print('ðŸ§  Extracting features...')\n",
    "        subprocess.run([\n",
    "            '/home/malves/miniconda3/envs/KPGT/bin/python',\n",
    "            '/home/malves/predator/KPGT/scripts/extract_features.py',\n",
    "            '--config', 'base',\n",
    "            '--model_path', '/home/malves/predator/KPGT/models/pretrained/base/base.pth',\n",
    "            '--data_path', '/home/malves/predator/KPGT/datasets/',\n",
    "            '--gpu', str(gpu),\n",
    "            '--dataset', folder\n",
    "        ])\n",
    "    finally:\n",
    "        os.chdir(original_path)\n",
    "\n",
    "    data = np.load(f'{dataset_path}/kpgt_base.npz')\n",
    "    fps_array = data['fps']\n",
    "\n",
    "    os.system(f'rm -r {dataset_path}')\n",
    "    return fps_array\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Main embedding computation for a dataset split\n",
    "def compute_kpgt_embeddings_for_dataset(csv_paths, output_fp_cache_path, gpu=6):\n",
    "    all_smiles = set()\n",
    "    for path in csv_paths:\n",
    "        df = pd.read_csv(path)\n",
    "        all_smiles.update(df[\"smiles\"])\n",
    "    all_smiles = sorted(list(all_smiles))  # order for stable mapping\n",
    "\n",
    "    print(f\"ðŸ§¬ Total unique SMILES: {len(all_smiles)}\")\n",
    "    fps_array = smiles_to_embeddings(all_smiles, gpu=gpu)\n",
    "    smiles_to_fp = {smi: fps_array[i] for i, smi in enumerate(all_smiles)}\n",
    "\n",
    "    with open(output_fp_cache_path, \"wb\") as f:\n",
    "        pickle.dump(smiles_to_fp, f)\n",
    "\n",
    "    print(f\"âœ… Embeddings saved to: {output_fp_cache_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a61ab24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 25 CSV files for RAW\n",
      "ðŸ§¬ Total unique SMILES: 18780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=32)]: Done 936 tasks      | elapsed:    5.1s\n",
      "[Parallel(n_jobs=32)]: Done 2336 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=32)]: Done 4136 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=32)]: Done 6336 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=32)]: Done 8936 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=32)]: Done 11936 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=32)]: Done 15336 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=32)]: Done 18780 out of 18780 | elapsed:   30.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graphs\n",
      "extracting fingerprints\n",
      "saving fingerprints\n",
      "extracting molecular descriptors\n",
      "ðŸ§  Extracting features.../18780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted features were saved at /home/malves/predator/KPGT/datasets//16-04-2025_00-47-00/kpgt_base.npz\n",
      "âœ… Embeddings saved to: /home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/raw/kpgt_embeddings_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "# RAW\n",
    "root = \"/home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/raw\"\n",
    "csv_paths = glob(os.path.join(root, \"raw_*.csv\"))\n",
    "print(\"ðŸ“„ Found\", len(csv_paths), \"CSV files for RAW\")\n",
    "compute_kpgt_embeddings_for_dataset(csv_paths, os.path.join(root, \"kpgt_embeddings_cache.pkl\"), gpu=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08a945b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 25 CSV files for H37Rv\n",
      "ðŸ§¬ Total unique SMILES: 14187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorchUsing backend: pytorch\n",
      "\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorchUsing backend: pytorch\n",
      "\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "[Parallel(n_jobs=32)]: Done 136 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=32)]: Done 744 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=32)]: Done 2144 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=32)]: Done 3944 tasks      | elapsed:    9.3s\n",
      "[Parallel(n_jobs=32)]: Done 6144 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=32)]: Done 8744 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=32)]: Done 11744 tasks      | elapsed:   21.3s\n",
      "[Parallel(n_jobs=32)]: Done 14124 out of 14187 | elapsed:   24.5s remaining:    0.1s\n",
      "[Parallel(n_jobs=32)]: Done 14187 out of 14187 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graphs\n",
      "extracting fingerprints\n",
      "saving fingerprints\n",
      "extracting molecular descriptors\n",
      "ðŸ§  Extracting features.../14187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted features were saved at /home/malves/predator/KPGT/datasets//16-04-2025_01-21-09/kpgt_base.npz\n",
      "âœ… Embeddings saved to: /home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/h37rv/kpgt_embeddings_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "# H37Rv\n",
    "root = \"/home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/h37rv\"\n",
    "csv_paths = glob(os.path.join(root, \"h37rv_*.csv\"))\n",
    "print(\"ðŸ“„ Found\", len(csv_paths), \"CSV files for H37Rv\")\n",
    "compute_kpgt_embeddings_for_dataset(csv_paths, os.path.join(root, \"kpgt_embeddings_cache.pkl\"), gpu=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09e31c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Found 25 CSV files for NR\n",
      "ðŸ§¬ Total unique SMILES: 18402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "WARNING:root:No normalization for BCUT2D_MWHI\n",
      "WARNING:root:No normalization for BCUT2D_MWLOW\n",
      "WARNING:root:No normalization for BCUT2D_CHGHI\n",
      "WARNING:root:No normalization for BCUT2D_CHGLO\n",
      "WARNING:root:No normalization for BCUT2D_LOGPHI\n",
      "WARNING:root:No normalization for BCUT2D_LOGPLOW\n",
      "WARNING:root:No normalization for BCUT2D_MRHI\n",
      "WARNING:root:No normalization for BCUT2D_MRLOW\n",
      "[Parallel(n_jobs=32)]: Using backend LokyBackend with 32 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "constructing graphs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "[Parallel(n_jobs=32)]: Done 162 tasks      | elapsed:    3.3s\n",
      "[Parallel(n_jobs=32)]: Done 1032 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=32)]: Done 2432 tasks      | elapsed:    6.9s\n",
      "[Parallel(n_jobs=32)]: Done 4232 tasks      | elapsed:    9.8s\n",
      "[Parallel(n_jobs=32)]: Done 6432 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=32)]: Done 9032 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=32)]: Done 12032 tasks      | elapsed:   21.0s\n",
      "[Parallel(n_jobs=32)]: Done 15432 tasks      | elapsed:   25.6s\n",
      "[Parallel(n_jobs=32)]: Done 18402 out of 18402 | elapsed:   29.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving graphs\n",
      "extracting fingerprints\n",
      "saving fingerprints\n",
      "extracting molecular descriptors\n",
      "ðŸ§  Extracting features.../18402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The extracted features were saved at /home/malves/predator/KPGT/datasets//16-04-2025_01-36-42/kpgt_base.npz\n",
      "âœ… Embeddings saved to: /home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/nr/kpgt_embeddings_cache.pkl\n"
     ]
    }
   ],
   "source": [
    "# NR\n",
    "root = \"/home/malves/predinhib_mtb/data/cv/raw_h37rv_nr/folds/nr\"\n",
    "csv_paths = glob(os.path.join(root, \"nr_*.csv\"))\n",
    "print(\"ðŸ“„ Found\", len(csv_paths), \"CSV files for NR\")\n",
    "compute_kpgt_embeddings_for_dataset(csv_paths, os.path.join(root, \"kpgt_embeddings_cache.pkl\"), gpu=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf24beb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "predinhib",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
